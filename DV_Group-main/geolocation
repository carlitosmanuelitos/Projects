#!pip install geopy pycountry
#!pip install --use-pep517 googlemaps

import pandas as pd
import numpy as np
from geopy.geocoders import GoogleV3
import googlemaps
import boto3
from botocore.exceptions import ClientError
import pycountry

import logging
from tqdm import tqdm
from typing import Tuple, Optional, Dict
from datetime import datetime
from pathlib import Path
import json
import unicodedata
import re
import time
import os

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


# GENERATE TESTING DATA
def reduce_csv_files(order_file, pos_file, output_order_file, output_pos_file, percentage=0.05):
    # Load the CSV files with delimiter ';'
    orders_df = pd.read_csv(order_file, delimiter=';')
    pos_df = pd.read_csv(pos_file, delimiter=';')

    # Function to reduce the size of the DataFrame by randomly deleting lines
    def reduce_size(df, percentage):
        # Calculate the number of rows to keep
        num_rows_to_keep = int(len(df) * percentage)
        # Randomly sample the rows to keep
        reduced_df = df.sample(n=num_rows_to_keep, random_state=1)
        return reduced_df

    # Reduce the size of both DataFrames
    reduced_orders_df = reduce_size(orders_df, percentage)
    reduced_pos_df = reduce_size(pos_df, percentage)

    # Save the reduced DataFrames back to CSV files
    reduced_orders_df.to_csv(output_order_file, index=False, sep=';')
    reduced_pos_df.to_csv(output_pos_file, index=False, sep=';')

    print(f"The files have been reduced to {percentage*100}% of their original size and saved as '{output_order_file}' and '{output_pos_file}'.")

# Example usage
reduce_csv_files('CZ_ORDER_DATA.csv', 'CZ_POS_DATA_GUID.csv', 'testing_CZ_ORDER.csv', 'testing_CZ_POS.csv')


# IAM ISSUES & ACCESS POLICIES

def get_current_iam_role():
    # Create an STS client
    sts_client = boto3.client('sts')

    # Get the identity of the caller
    identity = sts_client.get_caller_identity()

    # Print the ARN of the role
    print(f"User ARN: {identity['Arn']}")
    print(f"Account: {identity['Account']}")
    print(f"User ID: {identity['UserId']}")

# Example usage
get_current_iam_role()


# ------- PART0. API KEYS ACCESS MANAGMENT
def get_secret():
    secret_name = "CommerceReporting/GeoLocation"
    region_name = "eu-west-1"

    # Create a Secrets Manager client
    session = boto3.session.Session()
    client = session.client(
        service_name='secretsmanager',
        region_name=region_name
    )

    try:
        get_secret_value_response = client.get_secret_value(
            SecretId=secret_name
        )
    except ClientError as e:
        error_code = e.response['Error']['Code']
        if error_code == 'AccessDeniedException':
            print("You do not have sufficient access to perform this action. Please check IAM access policies")
        elif error_code == 'NotAuthorized':
            print("You do not have permission to perform this action. Please check IAM access policies")
        else:
            print(f"An unknown error occurred: {e}")
        raise e

    # Parse the secret string into a dictionary
    secret = json.loads(get_secret_value_response['SecretString'])

    geocoding_api_key = secret['google_api']

    # Return the API keys
    return geocoding_api_key

# Example usage
geocoding_api_key = get_secret()
print(f"Geocoding API Key: {geocoding_api_key}")




#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ----------------------------------------------------PART 1 PART 1 PART 1 PART 1 ---------------------------------------------------------------------- #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####


class GeoLocationMapper:
    """A class to handle geolocation mapping using Google Maps API."""
    
    def __init__(self, api_key: str, cache_file: str = 'geolocation_cache.json'):
        """
        Initialize the GeoLocationMapper.
        
        Args:
            api_key (str): Google Maps API key
            cache_file (str): Path to the cache file
        """
        self.api_key = api_key
        self.cache_file = cache_file
        self.geolocator = GoogleV3(api_key=api_key)
        self.cache = self._load_cache()
        self.total_calls = 0
        self.rate_limit_delay = 0.1  # 100ms delay between API calls
        
        # Configure logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'geolocation_mapping_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
                logging.StreamHandler()
            ]
        )

    def _load_cache(self) -> Dict:
        """Load the geolocation cache from file."""
        try:
            if os.path.exists(self.cache_file):
                with open(self.cache_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return {}
        except Exception as e:
            logging.error(f"Error loading cache: {e}")
            return {}

    def _save_cache(self) -> None:
        """Save the geolocation cache to file."""
        try:
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(self.cache, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"Error saving cache: {e}")

    @staticmethod
    def normalize_text(text: str) -> str:
        """Normalize text to ASCII and remove hidden characters."""
        if not isinstance(text, str):
            return text
        # Normalize to ASCII
        text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')
        # Remove hidden characters
        text = ''.join(c for c in text if c.isprintable())
        # Standardize whitespace
        text = re.sub(r'\s+', ' ', text.strip())
        return text

    @staticmethod
    def get_country_name(country_code: str) -> str:
        """Get full country name from country code."""
        try:
            return pycountry.countries.get(alpha_2=country_code).name
        except (AttributeError, KeyError):
            logging.warning(f"Country code '{country_code}' not found")
            return country_code

    def get_lat_long(self, address_components: dict) -> Tuple[Optional[float], Optional[float]]:
        """
        Get latitude and longitude for an address.
        
        Args:
            address_components (dict): Dictionary containing address components
                
        Returns:
            tuple: (latitude, longitude) or (None, None) if not found
        """
        try:
            # Validate required fields
            required_fields = ['street_name', 'postal_code', 'town', 'country_code']
            if not all(address_components.get(field) for field in required_fields):
                missing_fields = [f for f in required_fields if not address_components.get(f)]
                logging.warning(f"Missing required fields: {missing_fields}")
                return None, None

            # Construct address string
            country = self.get_country_name(address_components['country_code'])
            address_parts = [
                f"{address_components['street_name']} {address_components.get('street_number', '')}".strip(),
                f"{address_components['postal_code']}",
                address_components['town'],
                country
            ]
            address = ', '.join(filter(None, address_parts))

            # Check cache
            if address in self.cache:
                logging.debug(f"Cache hit for address: {address}")
                return self.cache[address]

            # Rate limiting
            time.sleep(self.rate_limit_delay)

            # Geocode address
            location = self.geolocator.geocode(address)
            self.total_calls += 1

            if location:
                result = (location.latitude, location.longitude)
                self.cache[address] = result
                if self.total_calls % 100 == 0:  # Save cache periodically
                    self._save_cache()
                return result
            
            logging.warning(f"No location found for address: {address}")
            return None, None

        except Exception as e:
            logging.error(f"Error geocoding address: {e}")
            return None, None

    def process_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Process the input DataFrame and add geolocation data.
        
        Args:
            df (pd.DataFrame): Input DataFrame with address information
            
        Returns:
            pd.DataFrame: DataFrame with added latitude and longitude columns
        """
        # Normalize text columns
        text_columns = ['STREET NAME', 'TOWN', 'POSTAL CODE']
        for col in text_columns:
            if col in df.columns:
                df[col] = df[col].apply(self.normalize_text)

        # Create progress bar
        tqdm.pandas(desc="Mapping geolocations")

        # Apply geolocation mapping
        results = df.progress_apply(
            lambda row: self.get_lat_long({
                'street_name': row.get('STREET NAME'),
                'street_number': row.get('STREET NUMBER'),
                'postal_code': row.get('POSTAL CODE'),
                'town': row.get('TOWN'),
                'country_code': row.get('COUNTRY')
            }), 
            axis=1
        )
        
        df['Latitude'], df['Longitude'] = zip(*results)
        return df

    def map_geolocations(self, input_file: str, output_file: str) -> None:
        """
        Main function to process input file and save results.
        
        Args:
            input_file (str): Path to input CSV file
            output_file (str): Path to output Excel file
        """
        try:
            # Read input file
            logging.info(f"Reading input file: {input_file}")
            data = pd.read_csv(input_file, delimiter=';', encoding='utf-8')
            
            # Process data
            df = self.process_dataframe(data)
            
            # Create unmapped addresses DataFrame
            unmapped_df = df[df['Latitude'].isna() | df['Longitude'].isna()]
            
            # Save results
            with pd.ExcelWriter(output_file) as writer:
                df.to_excel(writer, sheet_name='Coordinates', index=False)
                unmapped_df.to_excel(writer, sheet_name='Unmapped', index=False)
            
            # Log statistics
            self._log_statistics(df, unmapped_df)
            
            # Save final cache
            self._save_cache()
            
        except Exception as e:
            logging.error(f"Error processing file: {e}")
            raise

    def _log_statistics(self, df: pd.DataFrame, unmapped_df: pd.DataFrame) -> None:
        """Log processing statistics."""
        unmapped_count = len(unmapped_df)
        total_rows = len(df)
        unmapped_percentage = (unmapped_count / total_rows) * 100 if total_rows > 0 else 0
        
        logging.info(f"Processing completed:")
        logging.info(f"Total addresses processed: {total_rows}")
        logging.info(f"Successfully mapped: {total_rows - unmapped_count}")
        logging.info(f"Failed to map: {unmapped_count} ({unmapped_percentage:.2f}%)")
        logging.info(f"Unique addresses in cache: {len(self.cache)}")
        logging.info(f"Total API calls made: {self.total_calls}")


# Example usage:
mapper = GeoLocationMapper(api_key=geocoding_api_key)
mapper.map_geolocations(
    input_file='testing_DE_ORDER.csv',
    output_file='testing_DE_ORDER_mapped.xlsx'
)


#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ----------------------------------------------------PART 2 PART 2 PART 2 PART 2 ---------------------------------------------------------------------- #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####
#### ------------------------------------------------------------------------------------------------------------------------------------------------------ #####


import pandas as pd
import numpy as np
from googlemaps import Client
import logging
from datetime import datetime
from pathlib import Path
from tqdm import tqdm
import json
from typing import Dict, List, Tuple, Optional
import time
from concurrent.futures import ThreadPoolExecutor


class StoreDistanceMapper:
    """Handles mapping of orders to stores with distance calculations."""
    
    def __init__(self, api_key: str, cache_file: str = 'distance_cache.json'):
        """Initialize the mapper with API key and cache file."""
        self.gmaps = Client(key=api_key)
        self.cache_file = cache_file
        self.distance_cache = self._load_cache()
        self.api_calls = 0
        self.cache_hits = 0
        
        # Configure logging
        log_file = f'store_mapping_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )

    def _load_cache(self) -> Dict:
        """Load distance cache from file."""
        try:
            if Path(self.cache_file).exists():
                with open(self.cache_file, 'r') as f:
                    return json.load(f)
            return {}
        except Exception as e:
            logging.error(f"Error loading cache: {e}")
            return {}

    def _save_cache(self) -> None:
        """Save distance cache to file."""
        try:
            with open(self.cache_file, 'w') as f:
                json.dump(self.distance_cache, f)
        except Exception as e:
            logging.error(f"Error saving cache: {e}")

    @staticmethod
    def haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
        """Calculate haversine distance between two points."""
        lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])
        dlat, dlon = lat2 - lat1, lon2 - lon1
        a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2
        return 6367 * 2 * np.arcsin(np.sqrt(a))

    def get_drivable_distance(self, origin: Tuple[float, float], 
                            destination: Tuple[float, float]) -> Optional[float]:
        """Get drivable distance between two points with caching."""
        cache_key = f"{origin}_{destination}"
        
        if cache_key in self.distance_cache:
            self.cache_hits += 1
            logging.debug(f"Cache hit for distance: {cache_key}")
            return self.distance_cache[cache_key]
        
        try:
            time.sleep(0.1)  # Rate limiting
            self.api_calls += 1
            result = self.gmaps.distance_matrix(
                origins=[origin],
                destinations=[destination],
                mode='driving',
                units='metric'
            )
            
            if result['status'] == 'OK':
                distance = result['rows'][0]['elements'][0]['distance']['value'] / 1000
                self.distance_cache[cache_key] = distance
                
                # Periodic cache saving
                if self.api_calls % 100 == 0:
                    self._save_cache()
                    
                return distance
            else:
                logging.warning(f"API returned non-OK status: {result['status']}")
                return None
                
        except Exception as e:
            logging.error(f"Error calculating drivable distance: {e}")
            return None

    def _format_closest_store_row(self, order: pd.Series, store_info: Dict) -> Dict:
        """Format the closest store information into a row dictionary."""
        return {
            'DATE': order.get('DATE', ''),
            'COUNTRY': order.get('COUNTRY', ''),
            'ORDER': order.get('ORDER', ''),
            'CART CODE': order.get('CART CODE', ''),
            'ORDERCHANNEL': order.get('ORDERCHANNEL', ''),
            'ORDERTYPE': order.get('ORDERTYPE', ''),
            'PMIORDERSTATUS': order.get('PMIORDERSTATUS', ''),
            'BASE STORE': order.get('BASE STORE', ''),
            'DELIVERY MODE': order.get('Delivery Mode', ''),
            'DELIVERY STATUS': order.get('Delivery Status', ''),
            'CARRIER': order.get('CARRIER', ''),
            'SUBTOTAL': order.get('SUBTOTAL', ''),
            'TOWN': order.get('TOWN', ''),
            'POSTAL CODE': order.get('POSTAL CODE', ''),
            'STREET NAME': order.get('STREET NAME', ''),
            'STREET NUMBER': order.get('STREET NUMBER', ''),
            'Latitude': order['Latitude'],
            'Longitude': order['Longitude'],
            'Closest Store': store_info['store']['displayname'],
            'Linear Distance in KM': round(store_info['linear_distance'], 2),
            'Drivable Distance in KM': round(store_info['drivable_distance'], 2) if store_info['drivable_distance'] else None,
            'POS Latitude': store_info['store']['latitude'],
            'POS Longitude': store_info['store']['longitude']
        }

    def _format_nearby_stores_rows(self, order: pd.Series, stores: List[Dict], distance_type: str) -> List[Dict]:
        """Format nearby stores information into row dictionaries."""
        formatted_rows = []
        for store_info in stores:
            row = {
                'ORDER': order['ORDER'],
                'Order Address': f"{order.get('COUNTRY', '')}, {order.get('TOWN', '')}, {order.get('POSTAL CODE', '')}, {order.get('STREET NAME', '')}, {order.get('STREET NUMBER', '')}",
                'Latitude': order['Latitude'],
                'Longitude': order['Longitude'],
                'POS': store_info['store']['displayname'],
                'POS Latitude': store_info['store']['latitude'],
                'POS Longitude': store_info['store']['longitude']
            }
            
            if distance_type == 'linear':
                row['Linear Distance'] = round(store_info['linear_distance'], 2)
            else:  # drivable
                row['Drivable Distance'] = round(store_info['drivable_distance'], 2)
            
            formatted_rows.append(row)
            
        return formatted_rows

    def _update_store_counts(self, closest_df: pd.DataFrame, 
                           linear_df: pd.DataFrame, 
                           drivable_df: pd.DataFrame) -> pd.DataFrame:
        """Update the closest store DataFrame with store counts."""
        # Group by ORDER to count stores within range
        linear_counts = linear_df.groupby('ORDER').size().reset_index(name='Stores 5km Linear')
        drivable_counts = drivable_df.groupby('ORDER').size().reset_index(name='Stores 5km Drivable')
        
        # Merge counts with closest store DataFrame
        result_df = closest_df.merge(linear_counts, on='ORDER', how='left')
        result_df = result_df.merge(drivable_counts, on='ORDER', how='left')
        
        # Fill NaN values with 0 (for orders with no stores in range)
        result_df['Stores 5km Linear'] = result_df['Stores 5km Linear'].fillna(0).astype(int)
        result_df['Stores 5km Drivable'] = result_df['Stores 5km Drivable'].fillna(0).astype(int)
        
        return result_df

    def _find_closest_store(self, order: pd.Series, 
                           stores_df: pd.DataFrame) -> Dict:
        """Find the closest store using haversine distance first."""
        min_distance = float('inf')
        closest_store = None
        
        for _, store in stores_df.iterrows():
            distance = self.haversine(
                order['Latitude'], order['Longitude'],
                store['latitude'], store['longitude']
            )
            if distance < min_distance:
                min_distance = distance
                closest_store = store
        
        # Get drivable distance for closest store
        drivable_distance = self.get_drivable_distance(
            (order['Latitude'], order['Longitude']),
            (closest_store['latitude'], closest_store['longitude'])
        )
        
        return {
            'store': closest_store,
            'linear_distance': min_distance,
            'drivable_distance': drivable_distance
        }

    def _find_stores_within_linear(self, order: pd.Series, 
                                 stores_df: pd.DataFrame) -> List[Dict]:
        """Find all stores within 5km linear distance."""
        nearby_stores = []
        
        for _, store in stores_df.iterrows():
            distance = self.haversine(
                order['Latitude'], order['Longitude'],
                store['latitude'], store['longitude']
            )
            if distance <= 5:
                nearby_stores.append({
                    'store': store,
                    'linear_distance': distance
                })
        
        return nearby_stores

    def _get_drivable_stores(self, order: pd.Series, 
                            linear_stores: List[Dict]) -> List[Dict]:
        """Get drivable distances for stores within linear range."""
        drivable_stores = []
        
        for store_info in linear_stores:
            drivable_distance = self.get_drivable_distance(
                (order['Latitude'], order['Longitude']),
                (store_info['store']['latitude'], store_info['store']['longitude'])
            )
            
            if drivable_distance is not None and drivable_distance <= 5:
                store_info['drivable_distance'] = drivable_distance
                drivable_stores.append(store_info)
        
        return drivable_stores

    def _create_output_sheets(self, closest_stores: List[Dict],
                            linear_stores: List[Dict],
                            drivable_stores: List[Dict],
                            output_file: str) -> None:
        """Create and save all output sheets."""
        # Create DataFrames
        closest_df = pd.DataFrame(closest_stores)
        linear_df = pd.DataFrame(linear_stores)
        drivable_df = pd.DataFrame(drivable_stores)
        
        # Update store counts
        closest_df = self._update_store_counts(closest_df, linear_df, drivable_df)
        
        # Save to Excel
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            closest_df.to_excel(writer, sheet_name='Coordinates', index=False)
            linear_df.to_excel(writer, sheet_name='5km Stores Linear', index=False)
            drivable_df.to_excel(writer, sheet_name='5km Stores Drivable', index=False)

    def process_orders(self, orders_df: pd.DataFrame, 
                      stores_df: pd.DataFrame, output_file: str) -> None:
        """Process orders and create output sheets."""
        try:
            # Initialize result DataFrames
            closest_stores = []
            stores_within_5km_linear = []
            stores_within_5km_drivable = []
            
            # Process each order
            for idx, order in tqdm(orders_df.iterrows(), total=len(orders_df), 
                                 desc="Processing orders"):
                if pd.isna(order['Latitude']) or pd.isna(order['Longitude']):
                    continue
                
                order_location = (order['Latitude'], order['Longitude'])
                
                # Find closest store and stores within 5km
                closest_store_info = self._find_closest_store(order, stores_df)
                linear_stores = self._find_stores_within_linear(order, stores_df)
                drivable_stores = self._get_drivable_stores(order, linear_stores)
                
                # Update results
                closest_stores.append(self._format_closest_store_row(order, closest_store_info))
                stores_within_5km_linear.extend(self._format_nearby_stores_rows(order, linear_stores, 'linear'))
                stores_within_5km_drivable.extend(self._format_nearby_stores_rows(order, drivable_stores, 'drivable'))
            
            # Create output DataFrames
            self._create_output_sheets(
                closest_stores,
                stores_within_5km_linear,
                stores_within_5km_drivable,
                output_file
            )
            
            logging.info(f"Processing completed. API calls: {self.api_calls}, Cache hits: {self.cache_hits}")
            self._save_cache()
            
        except Exception as e:
            logging.error(f"Error in process_orders: {e}")
            raise


def main():
    """Main execution function."""
    try:
        # Configuration
        api_key = geocoding_api_key
        orders_file = 'DE_ORDER_DATA_geo.xlsx'
        stores_file = 'DE_POS_DATA_GUID_brand.csv'
        output_file = 'F_DE_distance_mapping_results.xlsx'
        
        # Load data
        orders_df = pd.read_excel(orders_file)
        stores_df = pd.read_csv(stores_file, delimiter=';', encoding='utf-8')
        
        # Initialize and run mapper
        mapper = StoreDistanceMapper(api_key)
        mapper.process_orders(orders_df, stores_df, output_file)
        
    except Exception as e:
        logging.error(f"Error in main execution: {e}")
        raise

if __name__ == "__main__":
    main()


3. Introduction
3.1. Assumptions
3.2. Technical context
3.3. Objective
3.4. Impacted components
4. Concept
5. Integration
5.1. Summary
5.2. Perf. KPI section for 3rd party integration & Observability matrix
5.3. Section 2
5.4. Section 3
6. APIs
